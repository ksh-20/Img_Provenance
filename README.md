# ğŸ” FakeLineage

> **Image Provenance Graph Construction for Deepfake-Aware Social Media Forensics**

FakeLineage is a full-stack research platform that traces the origin and spread of manipulated images across social networks. It combines deepfake detection, perceptual hashing, ELA forensics, steganography scanning, and interactive provenance graph visualization â€” all within a modern glassmorphism UI powered by FastAPI and React.

---

## âœ¨ Features

| Feature                         | Description                                                            |
| ------------------------------- | ---------------------------------------------------------------------- |
| ğŸ¤– **Deepfake Detection**       | Multi-signal ensemble (GAN artifacts, face-swap, noise analysis, ELA)  |
| ğŸ—º **Provenance Graph**         | Interactive lineage graph built with NetworkX + React Flow             |
| ğŸ” **ELA Heatmaps**             | Error Level Analysis heatmap with thermal colour mapping               |
| ğŸ“¡ **Social Spread Simulation** | Viral propagation simulation across Twitter, Instagram, TikTok, Reddit |
| ğŸ” **Steganography Scan**       | LSB (Least Significant Bit) anomaly detection for hidden data          |
| ğŸ“‹ **Forensics Report**         | Chain-of-custody report with JSON export                               |
| ğŸ›¡ **JWT Authentication**       | Secure register/login flow with bcrypt passwords                       |
| ğŸ—„ **MySQL Persistence**        | All analyses, provenance graphs, and social spreads stored per user    |
| ğŸ“¦ **Batch Analysis**           | Queue multiple images for parallel forensic processing                 |

---

## ğŸ— Architecture

```
Image Provenance/
â”œâ”€â”€ backend/                    # FastAPI Python backend
â”‚   â”œâ”€â”€ main.py                 # App entry point, CORS, router registration
â”‚   â”œâ”€â”€ database.py             # SQLAlchemy engine + get_db() dependency
â”‚   â”œâ”€â”€ .env                    # Environment variables (MySQL URL, JWT secret)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ schemas.py          # Pydantic request/response models
â”‚   â”‚   â””â”€â”€ db_models.py        # ORM: users, analyses, provenance_graphs, social_spreads
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ auth.py             # POST /register, POST /login, GET /me
â”‚   â”‚   â”œâ”€â”€ analysis.py         # POST /upload, POST /analyze/{id}
â”‚   â”‚   â”œâ”€â”€ provenance.py       # GET /graph/{id}
â”‚   â”‚   â”œâ”€â”€ social.py           # GET /spread/{id}
â”‚   â”‚   â””â”€â”€ reports.py          # GET /{id}, GET /dashboard/stats
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ auth_service.py     # bcrypt hashing, JWT encode/decode
â”‚       â”œâ”€â”€ deepfake.py         # Multi-signal deepfake detection pipeline
â”‚       â”œâ”€â”€ forensics.py        # ELA, manipulation region detection
â”‚       â”œâ”€â”€ hashing.py          # pHash, dHash, aHash similarity
â”‚       â”œâ”€â”€ metadata.py         # EXIF extraction, GPS parsing, steganography
â”‚       â”œâ”€â”€ graph.py            # Provenance graph construction (NetworkX)
â”‚       â””â”€â”€ social.py           # Social spread simulation
â”‚
â””â”€â”€ frontend/                   # React + TypeScript + Tailwind CSS
    â””â”€â”€ src/
        â”œâ”€â”€ api/client.ts       # Axios instance + auth interceptors + typed API calls
        â”œâ”€â”€ store/
        â”‚   â”œâ”€â”€ appStore.ts     # Zustand app-level state (analysis session)
        â”‚   â””â”€â”€ authStore.ts    # Zustand auth state (token, user) persisted to localStorage
        â”œâ”€â”€ components/
        â”‚   â”œâ”€â”€ Auth/           # ProtectedRoute
        â”‚   â”œâ”€â”€ Layout/         # Sidebar (user info + logout), Layout (Outlet)
        â”‚   â”œâ”€â”€ Upload/         # ImageDropzone (drag-and-drop)
        â”‚   â”œâ”€â”€ Analysis/       # ScoreBar, RadialGauge, VerdictCard, ScoreBreakdown
        â”‚   â”œâ”€â”€ Forensics/      # ELACanvas, ELAViewer, MetadataPanel
        â”‚   â”œâ”€â”€ Graph/          # ProvenanceNode, GraphStats, GraphLegend
        â”‚   â””â”€â”€ Reports/        # ReportSummary, EvidenceList, ChainOfCustody, ScoreRings
        â”œâ”€â”€ pages/
        â”‚   â”œâ”€â”€ Login.tsx       # Auth: login form
        â”‚   â”œâ”€â”€ Register.tsx    # Auth: register with password strength indicator
        â”‚   â”œâ”€â”€ Dashboard.tsx   # Overview stats + feature highlights
        â”‚   â”œâ”€â”€ Analysis.tsx    # Upload â†’ analyze â†’ ELA + metadata
        â”‚   â”œâ”€â”€ ProvenanceGraph.tsx  # Interactive React Flow lineage graph
        â”‚   â”œâ”€â”€ SocialTracker.tsx    # Viral spread charts (Recharts)
        â”‚   â”œâ”€â”€ BatchAnalysis.tsx    # Multi-image queue processing
        â”‚   â”œâ”€â”€ ForensicsReport.tsx  # Full chain-of-custody report
        â”‚   â””â”€â”€ Settings.tsx         # Thresholds, API config, toggles
        â””â”€â”€ types/index.ts      # Shared TypeScript types
```

---

## âš™ï¸ Prerequisites

| Tool    | Version |
| ------- | ------- |
| Python  | 3.11+   |
| Node.js | 18+     |
| MySQL   | 8.0+    |
| pip     | latest  |
| npm     | 9+      |

---

## ğŸš€ Quick Start

### 1. Clone the repository

```bash
git clone https://github.com/ksh-20/Img_Provenance.git
cd Img_Provenance
```

### 2. MySQL setup

```sql
-- In MySQL shell or Workbench:
CREATE DATABASE fakelineage CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
```

> Tables are **auto-created** by SQLAlchemy on first backend startup â€” no migrations needed.

### 3. Backend setup

```bash
cd backend

# Create and activate virtual environment
python -m venv venv
venv\Scripts\activate        # Windows
# source venv/bin/activate   # macOS/Linux

# Install dependencies
pip install -r requirements.txt
```

**Update `backend/.env`:**

```env
DATABASE_URL=mysql+pymysql://root:YOUR_PASSWORD@localhost:3306/fakelineage
SECRET_KEY=change-this-to-a-random-string-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=1440
```

**Start the backend:**

```bash
uvicorn main:app --reload --port 8000
```

The API will be available at `http://localhost:8000`.  
Interactive docs: `http://localhost:8000/docs`

### 4. Frontend setup

```bash
cd frontend
npm install
npm run dev
```

The app will be available at `http://localhost:5173`.

---

## ğŸ”‘ Authentication Flow

```
Register (/register) â”€â”€â†’ POST /api/auth/register â”€â”€â†’ JWT token â†’ stored in localStorage
Login    (/login)    â”€â”€â†’ POST /api/auth/login    â”€â”€â†’ JWT token â†’ stored in localStorage
All protected routes â”€â”€â†’ Axios interceptor injects "Authorization: Bearer <token>"
401 response         â”€â”€â†’ Auto-logout + redirect to /login
```

**Endpoints:**

| Method | Endpoint             | Description                                |
| ------ | -------------------- | ------------------------------------------ |
| `POST` | `/api/auth/register` | Register new user (JSON body)              |
| `POST` | `/api/auth/login`    | Login with email + password (form-encoded) |
| `GET`  | `/api/auth/me`       | Get current user profile + analysis count  |
| `POST` | `/api/auth/logout`   | Client-side logout signal                  |

---

## ğŸ“¡ API Reference

### Images

| Method | Endpoint                         | Description                                 |
| ------ | -------------------------------- | ------------------------------------------- |
| `POST` | `/api/images/upload`             | Upload image (multipart/form-data)          |
| `POST` | `/api/images/analyze/{image_id}` | Run full deepfake + ELA + metadata analysis |
| `GET`  | `/api/images/{image_id}`         | Get image info + perceptual hashes          |
| `GET`  | `/api/images/ela/{image_id}`     | Get ELA heatmap array                       |

### Provenance

| Method | Endpoint                               | Description                       |
| ------ | -------------------------------------- | --------------------------------- |
| `GET`  | `/api/provenance/graph/{image_id}`     | Build and return provenance graph |
| `GET`  | `/api/provenance/integrity/{image_id}` | Get chain integrity score         |

### Social

| Method | Endpoint                        | Description                            |
| ------ | ------------------------------- | -------------------------------------- |
| `GET`  | `/api/social/spread/{image_id}` | Simulate viral spread across platforms |

### Reports

| Method | Endpoint                       | Description                    |
| ------ | ------------------------------ | ------------------------------ |
| `GET`  | `/api/reports/{image_id}`      | Generate full forensics report |
| `GET`  | `/api/reports/dashboard/stats` | Aggregate dashboard statistics |

### Health

```bash
curl http://localhost:8000/health
# {"status":"healthy","service":"FakeLineage","database":"connected"}
```

---

## ğŸ“Š Database Schema

```
users
â”œâ”€â”€ id (PK)
â”œâ”€â”€ username (unique)
â”œâ”€â”€ email (unique)
â”œâ”€â”€ hashed_password
â”œâ”€â”€ is_active
â”œâ”€â”€ created_at
â””â”€â”€ last_login

analyses
â”œâ”€â”€ id (PK)
â”œâ”€â”€ user_id (FK â†’ users)
â”œâ”€â”€ image_id, filename, file_size, image_width, image_height, image_format
â”œâ”€â”€ verdict, deepfake_score, gan_score, ela_score, face_swap_score, is_deepfake
â”œâ”€â”€ has_exif, camera_make, camera_model, stego_detected, suspicious_flags (JSON)
â””â”€â”€ analyzed_at

provenance_graphs
â”œâ”€â”€ id (PK), user_id (FK â†’ users), image_id
â”œâ”€â”€ node_count, edge_count, integrity_score, spread_depth, chain_broken
â””â”€â”€ created_at

social_spreads
â”œâ”€â”€ id (PK), user_id (FK â†’ users), image_id
â”œâ”€â”€ total_reach, viral_coefficient, platforms (JSON), bot_ratio
â””â”€â”€ created_at
```

---

## ğŸ–¥ Pages Overview

| Page             | Route         | Description                                  |
| ---------------- | ------------- | -------------------------------------------- |
| Login            | `/login`      | Email + password sign-in                     |
| Register         | `/register`   | Account creation with strength indicator     |
| Dashboard        | `/`           | Stats overview, feature cards                |
| Image Analysis   | `/analysis`   | Upload â†’ detect â†’ ELA â†’ metadata             |
| Provenance Graph | `/provenance` | Interactive BFS lineage graph                |
| Social Tracker   | `/social`     | Viral spread timeline and platform breakdown |
| Batch Analysis   | `/batch`      | Multi-image queue with progress tracking     |
| Forensics Report | `/report`     | Full chain-of-custody report + JSON export   |
| Settings         | `/settings`   | Model thresholds, API config, toggles        |

---

## ğŸ§ª Testing the Full Workflow

1. Open `http://localhost:5173/register` â€” create an account
2. Navigate to **Image Analysis** â†’ drag-and-drop any JPEG/PNG
3. Click **Analyze** â€” deepfake score, ELA heatmap, and metadata will appear
4. Navigate to **Provenance Graph** â†’ click **Build Graph**
5. Navigate to **Social Spread** â†’ click **Simulate Spread**
6. Navigate to **Forensics Report** â†’ click **Generate Report** â†’ Export JSON
7. Verify data in MySQL:
   ```sql
   USE fakelineage;
   SELECT id, username, email FROM users;
   SELECT image_id, verdict, deepfake_score FROM analyses;
   ```

---

## ğŸ›¡ Security Notes

- **Passwords** are hashed with bcrypt (cost factor 12) â€” never stored in plaintext
- **JWT tokens** expire after 24 hours (configurable via `ACCESS_TOKEN_EXPIRE_MINUTES`)
- **Change `SECRET_KEY`** in `.env` before any production deployment
- **`.env` is gitignored** â€” never commit credentials
- CORS is currently permissive (`"*"`) â€” restrict `allow_origins` in production

---

## ğŸ”§ Environment Variables

| Variable                      | Default                                                    | Description               |
| ----------------------------- | ---------------------------------------------------------- | ------------------------- |
| `DATABASE_URL`                | `mysql+pymysql://root:password@localhost:3306/fakelineage` | MySQL connection string   |
| `SECRET_KEY`                  | `fakelineage-super-secret-key-change-in-production`        | JWT signing key           |
| `ALGORITHM`                   | `HS256`                                                    | JWT algorithm             |
| `ACCESS_TOKEN_EXPIRE_MINUTES` | `1440`                                                     | Token lifetime (24 hours) |

---

## ğŸ“¦ Tech Stack

### Backend

- **[FastAPI](https://fastapi.tiangolo.com/)** â€” Async Python web framework
- **[SQLAlchemy](https://www.sqlalchemy.org/)** â€” ORM (MySQL via PyMySQL)
- **[Passlib + bcrypt](https://passlib.readthedocs.io/)** â€” Password hashing
- **[python-jose](https://python-jose.readthedocs.io/)** â€” JWT tokens
- **[Pillow](https://pillow.readthedocs.io/)** â€” Image processing
- **[NetworkX](https://networkx.org/)** â€” Provenance graph construction
- **[imagehash](https://github.com/JohannesBuchner/imagehash)** â€” Perceptual hashing

### Frontend

- **[React 18](https://react.dev/)** + **[TypeScript](https://www.typescriptlang.org/)**
- **[Vite](https://vitejs.dev/)** â€” Build tooling
- **[Tailwind CSS](https://tailwindcss.com/)** â€” Utility-first styling
- **[Framer Motion](https://www.framer.com/motion/)** â€” Animations
- **[React Flow](https://reactflow.dev/)** â€” Provenance graph visualization
- **[Recharts](https://recharts.org/)** â€” Social spread charts
- **[Zustand](https://zustand-demo.pmnd.rs/)** â€” State management
- **[Axios](https://axios-http.com/)** â€” HTTP client with interceptors

---

## ğŸ“ Key Configuration Files

| File                          | Purpose                           |
| ----------------------------- | --------------------------------- |
| `backend/.env`                | MySQL URL, JWT secret             |
| `backend/requirements.txt`    | Python dependencies               |
| `frontend/vite.config.ts`     | Dev server + API proxy to `:8000` |
| `frontend/tsconfig.app.json`  | TypeScript strict settings        |
| `frontend/tailwind.config.js` | Tailwind theme extensions         |

---

## âš ï¸ Research Notice

FakeLineage is an **experimental research tool** for studying image provenance and deepfake forensics. The deepfake detection pipeline uses heuristic signals â€” results should be **validated by domain experts** before use in legal, journalistic, or policy contexts.

---
